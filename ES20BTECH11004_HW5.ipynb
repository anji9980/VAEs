{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "2nd Solution"
      ],
      "metadata": {
        "id": "0UBel1EIdHvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.layers import Input, Dense, Lambda, Reshape\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Flatten the images into a 784-dimensional vector\n",
        "img_shape = x_train.shape[1:]\n",
        "input_dim = np.prod(img_shape)\n",
        "x_train = x_train.reshape((-1, input_dim))\n",
        "x_test = x_test.reshape((-1, input_dim))\n",
        "\n",
        "# Define the dimensions of the latent space\n",
        "latent_dim = 16\n",
        "\n",
        "# Define the encoder network\n",
        "inputs = Input(shape=(input_dim,))\n",
        "x = Dense(256, activation='relu')(inputs)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "z_mean = Dense(latent_dim)(x)\n",
        "z_log_var = Dense(latent_dim)(x)\n",
        "\n",
        "# Define the sampling function\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=1.)\n",
        "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
        "\n",
        "z = Lambda(sampling)([z_mean, z_log_var])\n",
        "\n",
        "# Define the decoder network\n",
        "decoder_inputs = Input(shape=(latent_dim,))\n",
        "x = Dense(128, activation='relu')(decoder_inputs)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "outputs = Dense(input_dim, activation='sigmoid')(x)\n",
        "decoder = Model(decoder_inputs, outputs)\n",
        "\n",
        "# Define the VAE model\n",
        "outputs = decoder(z)\n",
        "vae = Model(inputs, outputs)\n",
        "\n",
        "# Define the VAE loss function\n",
        "reconstruction_loss = K.sum(K.binary_crossentropy(inputs, outputs), axis=-1)\n",
        "kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "\n",
        "# Compile the VAE model\n",
        "vae.compile(optimizer='adam')\n",
        "\n",
        "# Train the VAE model\n",
        "vae.fit(x_train, epochs=30, batch_size=128, validation_data=(x_test, None))\n",
        "\n",
        "# Generate 64 images from the VAE\n",
        "z_sample = np.random.normal(size=(64, latent_dim))\n",
        "x_decoded = decoder.predict(z_sample)\n",
        "\n",
        "# Display the generated images\n",
        "fig, axs = plt.subplots(8, 8)\n",
        "for i in range(8):\n",
        "    for j in range(8):\n",
        "        axs[i, j].imshow(x_decoded[i * 8 + j].reshape(img_shape), cmap='gray')\n",
        "        axs[i, j].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hNbEec8WdLPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1st Solution"
      ],
      "metadata": {
        "id": "jjA2pMyRdM4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(X_train, _), (X_test, _) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Flatten the images\n",
        "X_train = X_train.reshape((len(X_train), -1))\n",
        "X_test = X_test.reshape((len(X_test), -1))\n",
        "\n",
        "# Set the hyperparameters\n",
        "hidden_dims = [32, 64, 128]\n",
        "reg_strength = 0.0001\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "for dim in hidden_dims:\n",
        "    # Define the input layer\n",
        "    input_img = Input(shape=X_train.shape[1])\n",
        "\n",
        "    # Define the encoder layers\n",
        "    encoded = Dense(dim, activation='relu',\n",
        "                    activity_regularizer=regularizers.l1(reg_strength))(input_img)\n",
        "\n",
        "    # Define the decoder layers\n",
        "    decoded = Dense(X_train.shape[1], activation='sigmoid')(encoded)\n",
        "\n",
        "    # Define the autoencoder model\n",
        "    autoencoder = Model(input_img, decoded)\n",
        "\n",
        "    # Compile the model\n",
        "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "    # Train the model\n",
        "    autoencoder.fit(X_train, X_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(X_test, X_test))\n",
        "\n",
        "    # Calculate reconstruction errors on the train and test datasets\n",
        "    train_loss = autoencoder.evaluate(X_train, X_train, verbose=0)\n",
        "    test_loss = autoencoder.evaluate(X_test, X_test, verbose=0)\n",
        "\n",
        "    print(f\"Hidden dimension: {dim}\")\n",
        "    print(f\"Train reconstruction error: {train_loss:.4f}\")\n",
        "    print(f\"Test reconstruction error: {test_loss:.4f}\")\n",
        "\n",
        "    # Display some reconstructions from the train and test datasets\n",
        "    decoded_imgs = autoencoder.predict(X_test)\n",
        "    n = 10\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(n):\n",
        "        # Display original images\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(X_test[i].reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "        # Display reconstructed images\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "rcHhyv6IdOwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3rd solution"
      ],
      "metadata": {
        "id": "BG7R8K-GdT4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the self-attention layer\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.query_conv = nn.Conv2d(in_channels, in_channels//8, kernel_size=1)\n",
        "        self.key_conv = nn.Conv2d(in_channels, in_channels//8, kernel_size=1)\n",
        "        self.value_conv = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, C, width, height = x.size()\n",
        "        proj_query = self.query_conv(x).view(batch_size, -1, width*height).permute(0, 2, 1)\n",
        "        proj_key = self.key_conv(x).view(batch_size, -1, width*height)\n",
        "        energy = torch.bmm(proj_query, proj_key)\n",
        "        attention = nn.functional.softmax(energy, dim=-1)\n",
        "        proj_value = self.value_conv(x).view(batch_size, -1, width*height)\n",
        "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
        "        out = out.view(batch_size, C, width, height)\n",
        "        out = self.gamma*out + x\n",
        "        return out\n",
        "\n",
        "# Define the CNN model with self-attention layer(s)\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.attention1 = SelfAttention(32)\n",
        "        self.attention2 = SelfAttention(64)\n",
        "        self.attention3 = SelfAttention(128)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(128*4*4, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.conv1(x))\n",
        "        x = self.attention1(x)\n",
        "        x = self.pool(x)\n",
        "        x = nn.functional.relu(self.conv2(x))\n",
        "        x = self.attention2(x)\n",
        "        x = self.pool(x)\n",
        "        x = nn.functional.relu(self.conv3(x))\n",
        "        x = self.attention3(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 128*4*4)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = nn.functional.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Set the random seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the device to CPU\n",
        "device = torch.device('cpu')\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10('./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "# Define the CNN model and optimizer\n",
        "model = CNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Y9RLyF4EdVky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(SelfAttention, self).__init__()\n",
        "\n",
        "        self.query_conv = nn.Conv2d(in_channels=in_channels, out_channels=in_channels // 8, kernel_size=1)\n",
        "        self.key_conv = nn.Conv2d(in_channels=in_channels, out_channels=in_channels // 8, kernel_size=1)\n",
        "        self.value_conv = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, channels, height, width = x.size()\n",
        "\n",
        "        proj_query = self.query_conv(x).view(batch_size, -1, height * width).permute(0, 2, 1)\n",
        "        proj_key = self.key_conv(x).view(batch_size, -1, height * width)\n",
        "\n",
        "        energy = torch.bmm(proj_query, proj_key)\n",
        "        attention = F.softmax(energy, dim=-1)\n",
        "\n",
        "        proj_value = self.value_conv(x).view(batch_size, -1, height * width)\n",
        "\n",
        "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
        "        out = out.view(batch_size, channels, height, width)\n",
        "\n",
        "        out = self.gamma * out + x\n",
        "        return out\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.attention1 = SelfAttention(in_channels=64)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.attention2 = SelfAttention(in_channels=128)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.fc = nn.Linear(in_features=256 * 8 * 8, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.attention1(x)\n",
        "\n",
        "        x = F.relu(F.max_pool2d(self.bn2(self.conv2(x)), 2))\n",
        "        x = self.attention2(x)\n",
        "\n",
        "        x = F.relu(F.max_pool2d(self.bn3(self.conv3(x)), 2))\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Instantiate the model and print the summary\n",
        "model = CNN()\n",
        "print(summary(model, (3, 32, 32)))"
      ],
      "metadata": {
        "id": "qXSEqdA6di3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define the transform to normalize the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load the CIFAR-10 training and test sets using DataLoader\n",
        "train_set = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "# Instantiate the model and define the loss function and optimizer\n",
        "model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model for a specified number of epochs\n",
        "num_epochs = 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished training')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        inputs, labels = data\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy on test set: %.2f %%' % (100 * correct / total))"
      ],
      "metadata": {
        "id": "6W5GB9bbdost"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}